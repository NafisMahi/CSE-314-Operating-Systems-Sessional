diff --git a/Makefile b/Makefile
index 39a99d7..b7232a6 100644
--- a/Makefile
+++ b/Makefile
@@ -117,6 +117,7 @@ mkfs/mkfs: mkfs/mkfs.c $K/fs.h $K/param.h
 
 UPROGS=\
 	$U/_cat\
+	$U/_cowtest\
 	$U/_echo\
 	$U/_forktest\
 	$U/_grep\
diff --git a/kernel/defs.h b/kernel/defs.h
index a3c962b..bd5f2cd 100644
--- a/kernel/defs.h
+++ b/kernel/defs.h
@@ -63,6 +63,9 @@ void            ramdiskrw(struct buf*);
 void*           kalloc(void);
 void            kfree(void *);
 void            kinit(void);
+int             kRefCount(void*);
+int             krefcnt(void* );
+int             freemem(void);
 
 // log.c
 void            initlog(int, struct superblock*);
@@ -106,6 +109,7 @@ void            yield(void);
 int             either_copyout(int user_dst, uint64 dst, void *src, uint64 len);
 int             either_copyin(void *dst, int user_src, uint64 src, uint64 len);
 void            procdump(void);
+int             nproc(void);
 
 // swtch.S
 void            swtch(struct context*, struct context*);
@@ -147,6 +151,8 @@ void            trapinit(void);
 void            trapinithart(void);
 extern struct spinlock tickslock;
 void            usertrapret(void);
+int             cow_page(pagetable_t, uint64);
+void*           cow_alloc(pagetable_t,uint64 );
 
 // uart.c
 void            uartinit(void);
diff --git a/kernel/kalloc.c b/kernel/kalloc.c
index 0699e7e..2320f72 100644
--- a/kernel/kalloc.c
+++ b/kernel/kalloc.c
@@ -1,82 +1,143 @@
 // Physical memory allocator, for user processes,
 // kernel stacks, page-table pages,
 // and pipe buffers. Allocates whole 4096-byte pages.
-
+ 
 #include "types.h"
 #include "param.h"
 #include "memlayout.h"
 #include "spinlock.h"
 #include "riscv.h"
 #include "defs.h"
-
-void freerange(void *pa_start, void *pa_end);
-
+ 
+void freerange(void* pa_start, void* pa_end);
+ 
 extern char end[]; // first address after kernel.
-                   // defined by kernel.ld.
-
+// defined by kernel.ld.
+ 
 struct run {
-  struct run *next;
+  struct run* next;
 };
-
+ 
 struct {
   struct spinlock lock;
-  struct run *freelist;
+  struct run* freelist;
 } kmem;
-
+ 
+int pos(void* pa) {
+  return (uint64)pa / PGSIZE;
+}
+ 
+struct ref_stru {
+  struct spinlock lock;
+  int counter[PHYSTOP / PGSIZE];
+  // array to remember number of process currently looking at this pagetable
+  // ei counter ta zero hoye gele only then oi page ta free korbo
+}ref;
+ 
+int krefcnt(void* pa) {
+  return ref.counter[(uint64)pa / PGSIZE];
+}
+ 
 void
 kinit()
 {
   initlock(&kmem.lock, "kmem");
+  initlock(&ref.lock, "ref");
   freerange(end, (void*)PHYSTOP);
 }
 
+
+int freemem(void)
+{
+  struct run *r;
+  r=kmem.freelist;
+
+  acquire(&kmem.lock);
+  int num_of_free_pages=0;
+  while(r)
+  {
+    num_of_free_pages++;
+    r=r->next;
+  }
+  
+  release(&kmem.lock);
+  
+  printf("Number of free pages: %d\n",num_of_free_pages);
+  return 0;
+}
+ 
 void
-freerange(void *pa_start, void *pa_end)
+freerange(void* pa_start, void* pa_end)
 {
-  char *p;
+  char* p;
   p = (char*)PGROUNDUP((uint64)pa_start);
-  for(; p + PGSIZE <= (char*)pa_end; p += PGSIZE)
+  for (; p + PGSIZE <= (char*)pa_end; p += PGSIZE) {
+    ref.counter[(uint64)p/PGSIZE] = 1;
     kfree(p);
+  }
 }
-
+ 
 // Free the page of physical memory pointed at by pa,
 // which normally should have been returned by a
 // call to kalloc().  (The exception is when
 // initializing the allocator; see kinit above.)
 void
-kfree(void *pa)
+kfree(void* pa)
 {
-  struct run *r;
-
-  if(((uint64)pa % PGSIZE) != 0 || (char*)pa < end || (uint64)pa >= PHYSTOP)
+  struct run* r;
+ 
+  if (((uint64)pa % PGSIZE) != 0 || (char*)pa < end || (uint64)pa >= PHYSTOP)
     panic("kfree");
-
+ 
   // Fill with junk to catch dangling refs.
-  memset(pa, 1, PGSIZE);
-
-  r = (struct run*)pa;
-
-  acquire(&kmem.lock);
-  r->next = kmem.freelist;
-  kmem.freelist = r;
-  release(&kmem.lock);
+  acquire(&ref.lock);
+  if (--ref.counter[(uint64)pa/ PGSIZE] == 0) {
+    release(&ref.lock);
+ 
+ 
+    r = (struct run*)pa;
+    memset(pa, 1, PGSIZE);
+    acquire(&kmem.lock);
+    r->next = kmem.freelist;
+    kmem.freelist = r;
+    release(&kmem.lock);
+  }
+  else {
+    release(&ref.lock);
+  }
 }
-
+ 
 // Allocate one 4096-byte page of physical memory.
 // Returns a pointer that the kernel can use.
 // Returns 0 if the memory cannot be allocated.
-void *
+void*
 kalloc(void)
 {
-  struct run *r;
-
+  struct run* r;
+ 
   acquire(&kmem.lock);
   r = kmem.freelist;
-  if(r)
+  if (r) {
     kmem.freelist = r->next;
+    acquire(&ref.lock);
+    ref.counter[(uint64)r / PGSIZE] = 1;
+    release(&ref.lock);
+  }
   release(&kmem.lock);
-
-  if(r)
+ 
+  if (r)
     memset((char*)r, 5, PGSIZE); // fill with junk
   return (void*)r;
 }
+ 
+ 
+int kRefCount(void* pa) {
+  if (((uint64)pa % PGSIZE) != 0 || (char*)pa < end || (uint64)pa >= PHYSTOP) {
+    panic("kAddressRefCount");
+    return -1;
+  }
+  acquire(&ref.lock);
+  ++ref.counter[(uint64)pa / PGSIZE];
+  release(&ref.lock);
+  return 0;
+}
\ No newline at end of file
diff --git a/kernel/proc.c b/kernel/proc.c
index 959b778..56a1f20 100644
--- a/kernel/proc.c
+++ b/kernel/proc.c
@@ -89,6 +89,27 @@ myproc(void)
   return p;
 }
 
+int nproc(void)
+{
+  struct proc *p;
+  //int running_proc=0;
+
+  acquire(&proc->lock);
+
+  for(p=proc;p<&proc[NPROC];p++ )
+  {
+    if(p->state!=UNUSED)
+    {
+       printf("Process ID: %d, Used pages: %d\n",p->pid,p->sz/PGSIZE);
+      //running_proc++;
+    }
+  }
+
+  release(&proc->lock);
+
+  return 0;
+}
+
 int
 allocpid()
 {
diff --git a/kernel/riscv.h b/kernel/riscv.h
index 20a01db..962e327 100644
--- a/kernel/riscv.h
+++ b/kernel/riscv.h
@@ -343,6 +343,7 @@ typedef uint64 *pagetable_t; // 512 PTEs
 #define PTE_W (1L << 2)
 #define PTE_X (1L << 3)
 #define PTE_U (1L << 4) // user can access
+#define PTE_F (1L<<8)
 
 // shift a physical address to the right place for a PTE.
 #define PA2PTE(pa) ((((uint64)pa) >> 12) << 10)
diff --git a/kernel/syscall.c b/kernel/syscall.c
index ed65409..6a71b9e 100644
--- a/kernel/syscall.c
+++ b/kernel/syscall.c
@@ -101,6 +101,7 @@ extern uint64 sys_unlink(void);
 extern uint64 sys_link(void);
 extern uint64 sys_mkdir(void);
 extern uint64 sys_close(void);
+extern uint64 sys_sysinfo(void);
 
 // An array mapping syscall numbers from syscall.h
 // to the function that handles the system call.
@@ -126,6 +127,7 @@ static uint64 (*syscalls[])(void) = {
 [SYS_link]    sys_link,
 [SYS_mkdir]   sys_mkdir,
 [SYS_close]   sys_close,
+[SYS_sysinfo] sys_sysinfo,
 };
 
 void
diff --git a/kernel/syscall.h b/kernel/syscall.h
index bc5f356..9db11e4 100644
--- a/kernel/syscall.h
+++ b/kernel/syscall.h
@@ -20,3 +20,4 @@
 #define SYS_link   19
 #define SYS_mkdir  20
 #define SYS_close  21
+#define SYS_sysinfo 22
diff --git a/kernel/sysproc.c b/kernel/sysproc.c
index 1de184e..ded3484 100644
--- a/kernel/sysproc.c
+++ b/kernel/sysproc.c
@@ -89,3 +89,12 @@ sys_uptime(void)
   release(&tickslock);
   return xticks;
 }
+
+uint64
+sys_sysinfo(void){
+
+
+  freemem();
+  nproc();
+  return 0;
+}
diff --git a/kernel/trap.c b/kernel/trap.c
index 512c850..6941fe9 100644
--- a/kernel/trap.c
+++ b/kernel/trap.c
@@ -37,52 +37,106 @@ void
 usertrap(void)
 {
   int which_dev = 0;
-
+ 
   if((r_sstatus() & SSTATUS_SPP) != 0)
     panic("usertrap: not from user mode");
-
+ 
   // send interrupts and exceptions to kerneltrap(),
   // since we're now in the kernel.
   w_stvec((uint64)kernelvec);
-
+ 
   struct proc *p = myproc();
-  
+ 
   // save user program counter.
   p->trapframe->epc = r_sepc();
-  
+ 
   if(r_scause() == 8){
     // system call
-
+ 
     if(killed(p))
       exit(-1);
-
+ 
     // sepc points to the ecall instruction,
     // but we want to return to the next instruction.
     p->trapframe->epc += 4;
-
+ 
     // an interrupt will change sepc, scause, and sstatus,
     // so enable only now that we're done with those registers.
     intr_on();
-
+ 
     syscall();
-  } else if((which_dev = devintr()) != 0){
+  }
+  else if ((which_dev = devintr()) != 0) {
     // ok
-  } else {
+  }
+  else if (r_scause() == 15 || r_scause() == 13) {
+    uint64 fault_va = r_stval();
+    if (fault_va >= p->sz
+      ||
+      cow_page(p->pagetable, fault_va) != 0
+      ||
+      cow_alloc(p->pagetable, PGROUNDDOWN(fault_va)) == 0
+ 
+      )
+      p->killed = 1;
+  }
+ 
+  else {
     printf("usertrap(): unexpected scause %p pid=%d\n", r_scause(), p->pid);
     printf("            sepc=%p stval=%p\n", r_sepc(), r_stval());
     setkilled(p);
   }
-
+ 
   if(killed(p))
     exit(-1);
-
+ 
   // give up the CPU if this is a timer interrupt.
   if(which_dev == 2)
     yield();
-
+ 
   usertrapret();
 }
 
+int cow_page(pagetable_t pagetable, uint64 va) {
+  if (va >= MAXVA) return -1;
+  pte_t* pte = walk(pagetable, va, 0);
+  if (pte == 0)
+    return -1;
+  if ((*pte & PTE_V) == 0)
+    return -1;
+  return (*pte & PTE_F ? 0 : -1);
+}
+ 
+void* cow_alloc(pagetable_t pagetable, uint64 va) {
+  if (va % PGSIZE != 0)
+    return  0;
+  uint64 pa = walkaddr(pagetable, va);
+  if (pa == 0)
+    return  0;
+ 
+  pte_t* pte = walk(pagetable, va, 0);
+ 
+  if (krefcnt((char*)pa) == 1) {
+    *pte |= PTE_W;
+    *pte &= ~PTE_F;
+    return (void*)pa;
+  }
+  else {
+    char* mem = kalloc();
+    if (mem == 0) return 0;
+    memmove(mem, (char*)pa, PGSIZE);
+    *pte &= ~PTE_V;
+    if (mappages(pagetable, va, PGSIZE, (uint64)mem, (PTE_FLAGS(*pte) | PTE_W) & ~PTE_F) != 0) {
+      kfree(mem);
+      *pte |= PTE_V;
+      return 0;
+    }
+    kfree((char*)PGROUNDDOWN(pa));
+    return mem;
+  }
+ 
+}
+
 //
 // return to user space
 //
diff --git a/kernel/vm.c b/kernel/vm.c
index 9f69783..f9c459b 100644
--- a/kernel/vm.c
+++ b/kernel/vm.c
@@ -5,57 +5,57 @@
 #include "riscv.h"
 #include "defs.h"
 #include "fs.h"
-
+ 
 /*
  * the kernel's page table.
  */
 pagetable_t kernel_pagetable;
-
+ 
 extern char etext[];  // kernel.ld sets this to end of kernel code.
-
+ 
 extern char trampoline[]; // trampoline.S
-
+ 
 // Make a direct-map page table for the kernel.
 pagetable_t
 kvmmake(void)
 {
   pagetable_t kpgtbl;
-
+ 
   kpgtbl = (pagetable_t) kalloc();
   memset(kpgtbl, 0, PGSIZE);
-
+ 
   // uart registers
   kvmmap(kpgtbl, UART0, UART0, PGSIZE, PTE_R | PTE_W);
-
+ 
   // virtio mmio disk interface
   kvmmap(kpgtbl, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);
-
+ 
   // PLIC
   kvmmap(kpgtbl, PLIC, PLIC, 0x400000, PTE_R | PTE_W);
-
+ 
   // map kernel text executable and read-only.
   kvmmap(kpgtbl, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);
-
+ 
   // map kernel data and the physical RAM we'll make use of.
   kvmmap(kpgtbl, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);
-
+ 
   // map the trampoline for trap entry/exit to
   // the highest virtual address in the kernel.
   kvmmap(kpgtbl, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);
-
+ 
   // allocate and map a kernel stack for each process.
   proc_mapstacks(kpgtbl);
-  
+ 
   return kpgtbl;
 }
-
+ 
 // Initialize the one kernel_pagetable
 void
 kvminit(void)
 {
   kernel_pagetable = kvmmake();
 }
-
+ 
 // Switch h/w page table register to the kernel's page table,
 // and enable paging.
 void
@@ -63,13 +63,13 @@ kvminithart()
 {
   // wait for any previous writes to the page table memory to finish.
   sfence_vma();
-
+ 
   w_satp(MAKE_SATP(kernel_pagetable));
-
+ 
   // flush stale entries from the TLB.
   sfence_vma();
 }
-
+ 
 // Return the address of the PTE in page table pagetable
 // that corresponds to virtual address va.  If alloc!=0,
 // create any required page-table pages.
@@ -87,7 +87,7 @@ walk(pagetable_t pagetable, uint64 va, int alloc)
 {
   if(va >= MAXVA)
     panic("walk");
-
+ 
   for(int level = 2; level > 0; level--) {
     pte_t *pte = &pagetable[PX(level, va)];
     if(*pte & PTE_V) {
@@ -101,7 +101,7 @@ walk(pagetable_t pagetable, uint64 va, int alloc)
   }
   return &pagetable[PX(0, va)];
 }
-
+ 
 // Look up a virtual address, return the physical address,
 // or 0 if not mapped.
 // Can only be used to look up user pages.
@@ -110,10 +110,10 @@ walkaddr(pagetable_t pagetable, uint64 va)
 {
   pte_t *pte;
   uint64 pa;
-
+ 
   if(va >= MAXVA)
     return 0;
-
+ 
   pte = walk(pagetable, va, 0);
   if(pte == 0)
     return 0;
@@ -124,7 +124,7 @@ walkaddr(pagetable_t pagetable, uint64 va)
   pa = PTE2PA(*pte);
   return pa;
 }
-
+ 
 // add a mapping to the kernel page table.
 // only used when booting.
 // does not flush TLB or enable paging.
@@ -134,7 +134,7 @@ kvmmap(pagetable_t kpgtbl, uint64 va, uint64 pa, uint64 sz, int perm)
   if(mappages(kpgtbl, va, sz, pa, perm) != 0)
     panic("kvmmap");
 }
-
+ 
 // Create PTEs for virtual addresses starting at va that refer to
 // physical addresses starting at pa. va and size might not
 // be page-aligned. Returns 0 on success, -1 if walk() couldn't
@@ -144,10 +144,10 @@ mappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm)
 {
   uint64 a, last;
   pte_t *pte;
-
+ 
   if(size == 0)
     panic("mappages: size");
-  
+ 
   a = PGROUNDDOWN(va);
   last = PGROUNDDOWN(va + size - 1);
   for(;;){
@@ -163,7 +163,7 @@ mappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm)
   }
   return 0;
 }
-
+ 
 // Remove npages of mappings starting from va. va must be
 // page-aligned. The mappings must exist.
 // Optionally free the physical memory.
@@ -172,10 +172,10 @@ uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free)
 {
   uint64 a;
   pte_t *pte;
-
+ 
   if((va % PGSIZE) != 0)
     panic("uvmunmap: not aligned");
-
+ 
   for(a = va; a < va + npages*PGSIZE; a += PGSIZE){
     if((pte = walk(pagetable, a, 0)) == 0)
       panic("uvmunmap: walk");
@@ -190,7 +190,7 @@ uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free)
     *pte = 0;
   }
 }
-
+ 
 // create an empty user page table.
 // returns 0 if out of memory.
 pagetable_t
@@ -203,7 +203,7 @@ uvmcreate()
   memset(pagetable, 0, PGSIZE);
   return pagetable;
 }
-
+ 
 // Load the user initcode into address 0 of pagetable,
 // for the very first process.
 // sz must be less than a page.
@@ -211,7 +211,7 @@ void
 uvmfirst(pagetable_t pagetable, uchar *src, uint sz)
 {
   char *mem;
-
+ 
   if(sz >= PGSIZE)
     panic("uvmfirst: more than a page");
   mem = kalloc();
@@ -219,7 +219,7 @@ uvmfirst(pagetable_t pagetable, uchar *src, uint sz)
   mappages(pagetable, 0, PGSIZE, (uint64)mem, PTE_W|PTE_R|PTE_X|PTE_U);
   memmove(mem, src, sz);
 }
-
+ 
 // Allocate PTEs and physical memory to grow process from oldsz to
 // newsz, which need not be page aligned.  Returns new size or 0 on error.
 uint64
@@ -227,10 +227,10 @@ uvmalloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz, int xperm)
 {
   char *mem;
   uint64 a;
-
+ 
   if(newsz < oldsz)
     return oldsz;
-
+ 
   oldsz = PGROUNDUP(oldsz);
   for(a = oldsz; a < newsz; a += PGSIZE){
     mem = kalloc();
@@ -247,7 +247,7 @@ uvmalloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz, int xperm)
   }
   return newsz;
 }
-
+ 
 // Deallocate user pages to bring the process size from oldsz to
 // newsz.  oldsz and newsz need not be page-aligned, nor does newsz
 // need to be less than oldsz.  oldsz can be larger than the actual
@@ -257,15 +257,15 @@ uvmdealloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz)
 {
   if(newsz >= oldsz)
     return oldsz;
-
+ 
   if(PGROUNDUP(newsz) < PGROUNDUP(oldsz)){
     int npages = (PGROUNDUP(oldsz) - PGROUNDUP(newsz)) / PGSIZE;
     uvmunmap(pagetable, PGROUNDUP(newsz), npages, 1);
   }
-
+ 
   return newsz;
 }
-
+ 
 // Recursively free page-table pages.
 // All leaf mappings must already have been removed.
 void
@@ -285,7 +285,7 @@ freewalk(pagetable_t pagetable)
   }
   kfree((void*)pagetable);
 }
-
+ 
 // Free user memory pages,
 // then free page-table pages.
 void
@@ -295,7 +295,7 @@ uvmfree(pagetable_t pagetable, uint64 sz)
     uvmunmap(pagetable, 0, PGROUNDUP(sz)/PGSIZE, 1);
   freewalk(pagetable);
 }
-
+ 
 // Given a parent process's page table, copy
 // its memory into a child's page table.
 // Copies both the page table and the
@@ -308,43 +308,51 @@ uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
   pte_t *pte;
   uint64 pa, i;
   uint flags;
-  char *mem;
-
-  for(i = 0; i < sz; i += PGSIZE){
-    if((pte = walk(old, i, 0)) == 0)
+ 
+ 
+  for (i = 0; i < sz; i += PGSIZE) {
+    if ((pte = walk(old, i, 0)) == 0)
       panic("uvmcopy: pte should exist");
-    if((*pte & PTE_V) == 0)
+    if ((*pte & PTE_V) == 0)
       panic("uvmcopy: page not present");
     pa = PTE2PA(*pte);
     flags = PTE_FLAGS(*pte);
-    if((mem = kalloc()) == 0)
-      goto err;
-    memmove(mem, (char*)pa, PGSIZE);
-    if(mappages(new, i, PGSIZE, (uint64)mem, flags) != 0){
-      kfree(mem);
-      goto err;
+ 
+    if (flags & PTE_W) {
+      flags = (flags | PTE_F) & ~PTE_W;
+      *pte = PA2PTE(pa) | flags;
+    }
+ 
+ 
+    if (mappages(new, i, PGSIZE, pa, flags) != 0) {
+      uvmunmap(new, 0, i / PGSIZE, 1);
+      return -1;
     }
+ 
+    if (kRefCount((void*)pa) != 0){
+      uvmunmap(new, 0, i / PGSIZE, 1);
+      return -1;
+  }
+ 
   }
   return 0;
-
- err:
-  uvmunmap(new, 0, i / PGSIZE, 1);
-  return -1;
+ 
+ 
 }
-
+ 
 // mark a PTE invalid for user access.
 // used by exec for the user stack guard page.
 void
 uvmclear(pagetable_t pagetable, uint64 va)
 {
   pte_t *pte;
-  
+ 
   pte = walk(pagetable, va, 0);
   if(pte == 0)
     panic("uvmclear");
   *pte &= ~PTE_U;
 }
-
+ 
 // Copy from kernel to user.
 // Copy len bytes from src to virtual address dstva in a given page table.
 // Return 0 on success, -1 on error.
@@ -352,24 +360,27 @@ int
 copyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len)
 {
   uint64 n, va0, pa0;
-
+ 
   while(len > 0){
     va0 = PGROUNDDOWN(dstva);
     pa0 = walkaddr(pagetable, va0);
-    if(pa0 == 0)
+    if (cow_page(pagetable, va0) == 0) {
+      pa0 = (uint64)cow_alloc(pagetable, va0);
+    }
+    if (pa0 == 0)
       return -1;
     n = PGSIZE - (dstva - va0);
     if(n > len)
       n = len;
     memmove((void *)(pa0 + (dstva - va0)), src, n);
-
+ 
     len -= n;
     src += n;
     dstva = va0 + PGSIZE;
   }
   return 0;
 }
-
+ 
 // Copy from user to kernel.
 // Copy len bytes to dst from virtual address srcva in a given page table.
 // Return 0 on success, -1 on error.
@@ -377,7 +388,7 @@ int
 copyin(pagetable_t pagetable, char *dst, uint64 srcva, uint64 len)
 {
   uint64 n, va0, pa0;
-
+ 
   while(len > 0){
     va0 = PGROUNDDOWN(srcva);
     pa0 = walkaddr(pagetable, va0);
@@ -387,14 +398,14 @@ copyin(pagetable_t pagetable, char *dst, uint64 srcva, uint64 len)
     if(n > len)
       n = len;
     memmove(dst, (void *)(pa0 + (srcva - va0)), n);
-
+ 
     len -= n;
     dst += n;
     srcva = va0 + PGSIZE;
   }
   return 0;
 }
-
+ 
 // Copy a null-terminated string from user to kernel.
 // Copy bytes to dst from virtual address srcva in a given page table,
 // until a '\0', or max.
@@ -404,7 +415,7 @@ copyinstr(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max)
 {
   uint64 n, va0, pa0;
   int got_null = 0;
-
+ 
   while(got_null == 0 && max > 0){
     va0 = PGROUNDDOWN(srcva);
     pa0 = walkaddr(pagetable, va0);
@@ -413,7 +424,7 @@ copyinstr(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max)
     n = PGSIZE - (srcva - va0);
     if(n > max)
       n = max;
-
+ 
     char *p = (char *) (pa0 + (srcva - va0));
     while(n > 0){
       if(*p == '\0'){
@@ -428,7 +439,7 @@ copyinstr(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max)
       p++;
       dst++;
     }
-
+ 
     srcva = va0 + PGSIZE;
   }
   if(got_null){
@@ -436,4 +447,4 @@ copyinstr(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max)
   } else {
     return -1;
   }
-}
+}
\ No newline at end of file
diff --git a/user/cowtest.c b/user/cowtest.c
new file mode 100644
index 0000000..9bf1ac7
--- /dev/null
+++ b/user/cowtest.c
@@ -0,0 +1,200 @@
+//
+// tests for copy-on-write fork() assignment.
+//
+
+#include "kernel/types.h"
+#include "kernel/memlayout.h"
+#include "user/user.h"
+
+// allocate more than half of physical memory,
+// then fork. this will fail in the default
+// kernel, which does not support copy-on-write.
+void
+simpletest()
+{
+  uint64 phys_size = PHYSTOP - KERNBASE;
+  int sz = (phys_size / 3) * 2;
+
+  printf("simple: ");
+  
+  char *p = sbrk(sz);
+  if(p == (char*)0xffffffffffffffffL){
+    printf("sbrk(%d) failed\n", sz);
+    exit(-1);
+  }
+
+  for(char *q = p; q < p + sz; q += 4096){
+    *(int*)q = getpid();
+  }
+  
+  sysinfo();
+  int pid = fork();
+  sysinfo();
+  if(pid < 0){
+    printf("fork() failed\n");
+    exit(-1);
+  }
+
+  if(pid == 0)
+    exit(0);
+
+  wait(0);
+
+  if(sbrk(-sz) == (char*)0xffffffffffffffffL){
+    printf("sbrk(-%d) failed\n", sz);
+    exit(-1);
+  }
+
+  printf("ok\n");
+}
+
+// three processes all write COW memory.
+// this causes more than half of physical memory
+// to be allocated, so it also checks whether
+// copied pages are freed.
+void
+threetest()
+{
+  uint64 phys_size = PHYSTOP - KERNBASE;
+  int sz = phys_size / 4;
+  int pid1, pid2;
+
+  printf("three: ");
+  
+  char *p = sbrk(sz);
+  if(p == (char*)0xffffffffffffffffL){
+    printf("sbrk(%d) failed\n", sz);
+    exit(-1);
+  }
+
+  pid1 = fork();
+  if(pid1 < 0){
+    printf("fork failed\n");
+    exit(-1);
+  }
+  if(pid1 == 0){
+    pid2 = fork();
+    if(pid2 < 0){
+      printf("fork failed");
+      exit(-1);
+    }
+    if(pid2 == 0){
+      for(char *q = p; q < p + (sz/5)*4; q += 4096){
+        *(int*)q = getpid();
+      }
+      for(char *q = p; q < p + (sz/5)*4; q += 4096){
+        if(*(int*)q != getpid()){
+          printf("wrong content\n");
+          exit(-1);
+        }
+      }
+      exit(-1);
+    }
+    for(char *q = p; q < p + (sz/2); q += 4096){
+      *(int*)q = 9999;
+    }
+    exit(0);
+  }
+
+  for(char *q = p; q < p + sz; q += 4096){
+    *(int*)q = getpid();
+  }
+
+  wait(0);
+
+  sleep(1);
+
+  for(char *q = p; q < p + sz; q += 4096){
+    if(*(int*)q != getpid()){
+      printf("wrong content\n");
+      exit(-1);
+    }
+  }
+
+  if(sbrk(-sz) == (char*)0xffffffffffffffffL){
+    printf("sbrk(-%d) failed\n", sz);
+    exit(-1);
+  }
+
+  printf("ok\n");
+}
+
+char junk1[4096];
+int fds[2];
+char junk2[4096];
+char buf[4096];
+char junk3[4096];
+
+// test whether copyout() simulates COW faults.
+void
+filetest()
+{
+  printf("file: ");
+  
+  buf[0] = 99;
+
+  for(int i = 0; i < 4; i++){
+    if(pipe(fds) != 0){
+      printf("pipe() failed\n");
+      exit(-1);
+    }
+    int pid = fork();
+    if(pid < 0){
+      printf("fork failed\n");
+      exit(-1);
+    }
+    if(pid == 0){
+      sleep(1);
+      if(read(fds[0], buf, sizeof(i)) != sizeof(i)){
+        printf("error: read failed\n");
+        exit(1);
+      }
+      sleep(1);
+      int j = *(int*)buf;
+      if(j != i){
+        printf("error: read the wrong value\n");
+        exit(1);
+      }
+      exit(0);
+    }
+    if(write(fds[1], &i, sizeof(i)) != sizeof(i)){
+      printf("error: write failed\n");
+      exit(-1);
+    }
+  }
+
+  int xstatus = 0;
+  for(int i = 0; i < 4; i++) {
+    wait(&xstatus);
+    if(xstatus != 0) {
+      exit(1);
+    }
+  }
+
+  if(buf[0] != 99){
+    printf("error: child overwrote parent\n");
+    exit(1);
+  }
+
+  printf("ok\n");
+}
+
+int
+main(int argc, char *argv[])
+{
+  simpletest();
+
+  // check that the first simpletest() freed the physical memory.
+  simpletest();
+
+  threetest();
+  threetest();
+  threetest();
+
+  filetest();
+
+  printf("ALL COW TESTS PASSED\n");
+
+  exit(0);
+}
+
diff --git a/user/user.h b/user/user.h
index 4d398d5..a800dfe 100644
--- a/user/user.h
+++ b/user/user.h
@@ -22,6 +22,7 @@ int getpid(void);
 char* sbrk(int);
 int sleep(int);
 int uptime(void);
+int sysinfo(void);
 
 // ulib.c
 int stat(const char*, struct stat*);
diff --git a/user/usys.pl b/user/usys.pl
index 01e426e..4f1f768 100755
--- a/user/usys.pl
+++ b/user/usys.pl
@@ -36,3 +36,4 @@ entry("getpid");
 entry("sbrk");
 entry("sleep");
 entry("uptime");
+entry("sysinfo");
